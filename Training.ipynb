{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, RL, max_simulation_days = 20, max_steps = 500):\n",
    "    \n",
    "    S = env.reset()\n",
    "    Rave, theta_mu, theta_sigma, w_valuefunc = RL.initialize()\n",
    "    \n",
    "    Rave_stepseries = []\n",
    "    theta_mu_stepseries = [] \n",
    "    theta_sigma_stepseries = [] \n",
    "    w_valuefunc_stepseries = []\n",
    "    Rave_stepseries.append(Rave)\n",
    "    theta_mu_stepseries.append(theta_mu)\n",
    "    theta_sigma_stepseries.append(theta_sigma)\n",
    "    w_valuefunc_stepseries.append(w_valuefunc)\n",
    "\n",
    "\n",
    "    G_stepseries = []\n",
    "    T_stepseries = []\n",
    "    t_stepseries = []\n",
    "    hs_stepseries = []\n",
    "    G_timeseries = []\n",
    "    T_timeseries = []\n",
    "    t_timeseries = []\n",
    "    G_stepseries.append(0)\n",
    "    T_stepseries.append(S[0])\n",
    "    t_stepseries.append(0)\n",
    "    hs_stepseries.append(S[1])\n",
    "    G_timeseries.append(0)\n",
    "    T_timeseries.append(S[0])\n",
    "    t_timeseries.append(0)\n",
    "\n",
    "\n",
    "    for step_iter in range(max_steps):\n",
    "\n",
    "        A = RL.choose_action(state = S)\n",
    "\n",
    "        Sp, R, T_StepTimeSeries, reward_StepTimeSeries, dt_step, t_StepTimeSeries, done = env.step(A)\n",
    "\n",
    "        Rave, theta_mu, theta_sigma, w_valuefunc = RL.learn(S, A, Sp, R, dt_step)\n",
    "\n",
    "\n",
    "        S = Sp\n",
    "        Rave_stepseries.append(Rave)\n",
    "        theta_mu_stepseries.append(theta_mu)\n",
    "        theta_sigma_stepseries.append(theta_sigma)\n",
    "        w_valuefunc_stepseries.append(w_valuefunc)\n",
    "\n",
    "\n",
    "        T_stepseries.append(S[0])\n",
    "        hs_stepseries.append(S[1])\n",
    "        G_stepseries.append(G_stepseries[-1] + R)\n",
    "        t_stepseries.append(t_stepseries[-1] + dt_step)\n",
    "\n",
    "        T_timeseries.extend(T_StepTimeSeries)\n",
    "        G_timeseries.extend(map(lambda x:x+G_stepseries[-2], reward_StepTimeSeries))\n",
    "        t_timeseries.extend(map(lambda x:x+t_stepseries[-2], t_StepTimeSeries))\n",
    "\n",
    "        if done:\n",
    "            print ('It took more than time_out ({} hr) to transition from the last state to a new state'.format(env.time_out/3600))                                                                                \n",
    "            break\n",
    "\n",
    "        if t_timeseries[-1]/(24*3600) > max_simulation_days:\n",
    "            print ('maximum simulation period ({} days) is reached'.format(max_simulation_days))\n",
    "            break\n",
    "    \n",
    "    return Rave_stepseries, theta_mu_stepseries, theta_sigma_stepseries, w_valuefunc_stepseries, t_stepseries, t_timeseries,\\\n",
    "           T_stepseries, T_timeseries, hs_stepseries, G_stepseries, G_timeseries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deterministic(env, RL, max_simulation_days = 20, max_steps = 500):\n",
    "    \n",
    "    S = env.reset()\n",
    "    \n",
    "    Rave, theta, w, v = RL.initialize()\n",
    "    \n",
    "    Rave_stepseries = []\n",
    "    theta_stepseries = [] \n",
    "    w_stepseries = [] \n",
    "    v_stepseries = []\n",
    "    Rave_stepseries.append(Rave)\n",
    "    theta_stepseries.append(theta)\n",
    "    w_stepseries.append(w)\n",
    "    v_stepseries.append(v)\n",
    "\n",
    "\n",
    "    G_stepseries = []\n",
    "    T_stepseries = []\n",
    "    t_stepseries = []\n",
    "    hs_stepseries = []\n",
    "    G_timeseries = []\n",
    "    T_timeseries = []\n",
    "    t_timeseries = []\n",
    "    G_stepseries.append(0)\n",
    "    T_stepseries.append(S[0])\n",
    "    t_stepseries.append(0)\n",
    "    hs_stepseries.append(S[1])\n",
    "    G_timeseries.append(0)\n",
    "    T_timeseries.append(S[0])\n",
    "    t_timeseries.append(0)\n",
    "\n",
    "\n",
    "    for step_iter in range(max_steps):\n",
    "\n",
    "        A = RL.choose_action(state = S)\n",
    "\n",
    "        Sp, R, T_StepTimeSeries, reward_StepTimeSeries, dt_step, t_StepTimeSeries, done = env.step(A)\n",
    "\n",
    "        Rave, theta, w, v = RL.learn(S, A, Sp, R, dt_step)\n",
    "\n",
    "\n",
    "        S = Sp\n",
    "        Rave_stepseries.append(Rave)\n",
    "        theta_stepseries.append(theta)\n",
    "        w_stepseries.append(w)\n",
    "        v_stepseries.append(v)\n",
    "\n",
    "\n",
    "        T_stepseries.append(S[0])\n",
    "        hs_stepseries.append(S[1])\n",
    "        G_stepseries.append(G_stepseries[-1] + R)\n",
    "        t_stepseries.append(t_stepseries[-1] + dt_step)\n",
    "\n",
    "        T_timeseries.extend(T_StepTimeSeries)\n",
    "        G_timeseries.extend(map(lambda x:x+G_stepseries[-2], reward_StepTimeSeries))\n",
    "        t_timeseries.extend(map(lambda x:x+t_stepseries[-2], t_StepTimeSeries))\n",
    "\n",
    "        if done:\n",
    "            print ('It took more than time_out ({} hr) to transition from the last state to a new state in the training'.format(env.time_out/3600))                                                                                \n",
    "            break\n",
    "\n",
    "        if t_timeseries[-1]/(24*3600) > max_simulation_days:\n",
    "            print ('maximum simulation period for training ({} days) is reached'.format(max_simulation_days))\n",
    "            break\n",
    "    \n",
    "    return Rave_stepseries, theta_stepseries, w_stepseries, v_stepseries, t_stepseries, t_timeseries,\\\n",
    "           T_stepseries, T_timeseries, hs_stepseries, G_stepseries, G_timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deterministic_Vent(env, RL, max_simulation_days = 20, max_steps = 500):\n",
    "    \n",
    "    S = env.reset()\n",
    "    Rave, theta, w, v = RL.initialize()\n",
    "    \n",
    "    Rave_stepseries = []\n",
    "    theta_stepseries = [] \n",
    "    w_stepseries = [] \n",
    "    v_stepseries = []\n",
    "    Rave_stepseries.append(Rave)\n",
    "    theta_stepseries.append(theta)\n",
    "    w_stepseries.append(w)\n",
    "    v_stepseries.append(v)\n",
    "\n",
    "    G_stepseries = []\n",
    "    T_stepseries = []\n",
    "    ro_stepseries = []\n",
    "    t_stepseries = []\n",
    "    hs_stepseries = []\n",
    "    vs_stepseries = []\n",
    "    G_timeseries = []\n",
    "    T_timeseries = []\n",
    "    ro_timeseries = []\n",
    "    t_timeseries = []\n",
    "\n",
    "    G_stepseries.append(0)\n",
    "    T_stepseries.append(S[0])\n",
    "    ro_stepseries.append(S[1])\n",
    "    t_stepseries.append(0)\n",
    "    hs_stepseries.append(S[2])\n",
    "    vs_stepseries.append(S[3])\n",
    "    G_timeseries.append(0)\n",
    "    T_timeseries.append(S[0])\n",
    "    ro_timeseries.append(S[1])\n",
    "    t_timeseries.append(0)\n",
    "    \n",
    "#     def choose_action(state):\n",
    "#         T, ro, hs, vs, zT, zro, aT, aro = state\n",
    "#         mu1 = (13*(1-hs)+17*hs)*zT + aT * (1-zT)\n",
    "#         mu2 = (900*(1-vs)+400*vs)*zro + aro*(1-zro)\n",
    "#         action = (mu1,mu2)\n",
    "#         return action\n",
    "\n",
    "    for step_iter in range(max_steps):\n",
    "        \n",
    "        print('before choose action')\n",
    "        A = RL.choose_action(state = S)\n",
    "        print('after choose action')\n",
    "        \n",
    "#         print('iteration: {}'.format(step_iter))\n",
    "#         print('S, A, Sp')\n",
    "#         print('S: T, ro, hs, vs, zT, zro, aT, aro')\n",
    "#         print(S)\n",
    "#         print(A)\n",
    "        \n",
    "#         A = choose_action(state = S)\n",
    "        Sp, R, T_StepTimeSeries, reward_StepTimeSeries, ro_StepTimeSeries, dt_step, t_StepTimeSeries, done = env.step(A)\n",
    "        \n",
    "#         print(Sp)\n",
    "    \n",
    "        \n",
    "        Rave, theta, w, v = RL.learn(S, A, Sp, R, dt_step)\n",
    "        \n",
    "#         print('hello')\n",
    "        \n",
    "        S = Sp\n",
    "        \n",
    "        Rave_stepseries.append(Rave)\n",
    "        theta_stepseries.append(theta)\n",
    "        w_stepseries.append(w)\n",
    "        v_stepseries.append(v)\n",
    "        \n",
    "        T_stepseries.append(S[0])\n",
    "        ro_stepseries.append(S[1])\n",
    "        hs_stepseries.append(S[2])\n",
    "        vs_stepseries.append(S[3])\n",
    "        G_stepseries.append(G_stepseries[-1] + R)\n",
    "        t_stepseries.append(t_stepseries[-1] + dt_step)\n",
    "\n",
    "        T_timeseries.extend(T_StepTimeSeries)\n",
    "        ro_timeseries.extend(ro_StepTimeSeries)\n",
    "        G_timeseries.extend(map(lambda x:x+G_stepseries[-2], reward_StepTimeSeries))\n",
    "        t_timeseries.extend(map(lambda x:x+t_stepseries[-2], t_StepTimeSeries))\n",
    "        \n",
    "        if done:\n",
    "            print ('It took more than time_out ({} hr) to transition from the last state to a new state'.format(env.time_out/3600))                                                                                \n",
    "            break\n",
    "\n",
    "        if t_timeseries[-1]/(24*3600) > max_simulation_days:\n",
    "            print ('maximum simulation period ({} days) is reached'.format(max_simulation_days))\n",
    "            break\n",
    "        \n",
    "#         print('hello2')\n",
    "        print(\"--------------------------------------------------------\")\n",
    "    \n",
    "    return Rave_stepseries, theta_stepseries, w_stepseries, v_stepseries,\\\n",
    "           t_stepseries, t_timeseries, ro_timeseries, vs_stepseries,\\\n",
    "           T_stepseries, T_timeseries, hs_stepseries, G_stepseries, G_timeseries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SmartBuildings",
   "language": "python",
   "name": "smartbuildings"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
